
# ACE-Step Data-Tool

## √úberblick

Das **ACE-Step Data-Tool** ist ein modulares Tool zur automatisierten Erstellung von Datens√§tzen f√ºr das ACE-Step Musikmodell. Es generiert vollautomatisch annotierte Datens√§tze aus Audiodaten, die f√ºr das Training von Musikmodellen verwendet werden k√∂nnen.

---

## Funktionen

### Songtext-Beschaffung (Lyrics Scraping)
Das Tool beschafft automatisch Songtexte zu den vorhandenen Audiodateien aus dem Internet, z. B. von [Genius.com](https://genius.com). Falls keine direkte URL verf√ºgbar ist, wird eine Suchanfrage auf Genius durchgef√ºhrt und das erste passende Ergebnis verwendet. Die Songtexte werden als reiner Text extrahiert (mittels `Requests` und `BeautifulSoup4`) und in einer Datei namens `__lyrics.txt` gespeichert.

- **Format:** In jeder `__lyrics.txt`-Datei werden K√ºnstler und Titel vermerkt, gefolgt vom vollst√§ndigen Liedtext (UTF-8 kodiert).
- **Hinweis:** Zwischen Anfragen wird eine kurze Pause eingelegt, um die Webseite nicht zu √ºberlasten. Falls kein Text gefunden wird, wird der Song als ‚Äûohne Lyrics‚Äú markiert.

> **Tipp:** Stellen Sie sicher, dass die Audiodateien korrekte K√ºnstler- und Titel-Tags haben, damit die Lyrics-Erkennung zuverl√§ssig funktioniert.

### Tempo-Analyse (BPM-Erkennung)
Das Tool ermittelt das ungef√§hre Tempo (in BPM ‚Äì Beats per Minute) aus dem Audiosignal. Daf√ºr wird die Bibliothek `Librosa` verwendet, die Onset-Erkennung und Rhythmusfunktionen nutzt, um das dominante Tempo in den ersten Sekunden des Songs abzusch√§tzen.

- Extreme Werte werden gefiltert, und Songs ohne erkennbares Tempo werden √ºbersprungen.

### Tag-Generierung (Stichwortliste)
F√ºr jeden Track wird eine Liste von Beschreibungstags generiert, die Genres, Stimmung, Instrumentierung, Vocal-Typ etc. beschreiben. Dies geschieht √ºber ein Large Language Model (LLM) mittels einer Ollama-API-Integration.

- **Input:** K√ºnstler, Titel, BPM, ein Auszug des Songtextes (z. B. 300 Zeichen) sowie optionale Stichworte aus Presets oder manuellen Eingaben.
- **Output:** 8-10 Tags in Kleinbuchstaben mit Bindestrich-Notation (z. B. `dark`, `bass-heavy`, `female-vocal`), einschlie√ülich eines BPM-Tags (Format: `bpm-XXX`).
- **Regeln:** Maximal 2 Genre-Tags, mindestens je ein Tag f√ºr Stimmung und Stil.

Die generierten Tags werden in einer Datei namens `_prompt.txt` gespeichert.

**Beispiel:**
```
bpm-125, male-vocal, rock, guitars, aggressive, anthem, pop-rock, upbeat, stadium, american
```

---


# üéß ACE-Step Data-Tool

Modulares Tool zur automatisierten Erstellung von Datens√§tzen f√ºr das ACE-Step Musikmodell.
Erstellt aus Audiodateien vollautomatisch begleitende Textdaten (Songtexte/Lyrics und Beschreibungstags) zur Trainingsdaten-Generierung.

## Inhalt

- √úbersicht
- Technische Architektur & Hauptfunktionen
- Installation & Setup
- Abh√§ngigkeiten
- Beispiele zur Nutzung
- Modellkompatibilit√§t & Hardware-Anforderungen
- Projektstruktur

## √úbersicht

ACE-Step Data-Tool ist ein Datenaufbereitungstool f√ºr Audiodaten, das speziell entwickelt wurde, um Trainingsdaten f√ºr das ACE-Step Musik-KI-Modell automatisch zu erstellen. Es durchsucht einen Ordner voller Audiodateien (z. B. Songs) und generiert f√ºr jeden Track zus√§tzliche Textdateien ‚Äì etwa die Songtexte (Lyrics) und eine Liste von Stichw√∂rtern/Tags, welche die Stimmung, Genre, Instrumentierung u.a. des St√ºcks beschreiben. Diese Dateien dienen als Begleitdaten, z. B. um ein KI-Modell wie ACE-Step mit passenden Eingabe-Prompts (Tags + Lyrics) zu trainieren oder um Musikmetadaten zu analysieren.

Hauptziele des Tools sind:

- **Automatisierung** (minimiert manuelle Schritte beim Datenaufbereiten)
- **Modularit√§t** (klare getrennte Komponenten f√ºr Lyrics, BPM, Tagging etc.)
- **Benutzerfreundlichkeit** (einfache Nutzung √ºber eine Web-Oberfl√§che oder Skripte, anpassbar an verschiedene Musikgenres und Modelle)

Das Tool richtet sich an Entwickler:innen und Forschende, die mit Python/Conda und Audiodatens√§tzen arbeiten, und erm√∂glicht ein schnelles Erzeugen von beschreibenden Metadaten zu einer Musiksammlung ‚Äì ohne veraltete, manuelle Workflows.

## Technische Architektur & Hauptfunktionen

Das ACE-Step Data-Tool besteht aus mehreren Komponenten, die in einer Verarbeitungspipeline zusammenwirken, unterst√ºtzt durch eine optionale Gradio Web-Oberfl√§che f√ºr komfortable Bedienung:

1.  **Verzeichnisscan & Dateiverarbeitung:** Standardm√§√üig erwartet das Tool einen Ordner (`data/` im Projektverzeichnis) mit Audiodateien (unterst√ºtzt: `.mp3`, `.wav`, `.flac`, `.m4a`). Alle Dateien (rekursiv in Unterordnern) werden eingelesen und nacheinander verarbeitet. F√ºr jeden Track werden Zwischenergebnisse und Logs angezeigt.
2.  **Metadaten-Extraktion:** Zu Beginn wird aus jeder Audiodatei der Artist und Title ermittelt (via ID3-Tags, mit der Bibliothek `TinyTag`). Diese Informationen dienen sp√§ter zur Lyrics-Suche. Falls eine Datei keine Tags besitzt (z. B. ungetaggte WAVs), wird der Dateiname als Titel genutzt.
    *   **Hinweis:** Stellen Sie sicher, dass die Audiodateien korrekte K√ºnstler- und Titeltags haben, damit die Lyrics-Erkennung zuverl√§ssig funktioniert.
3.  **Songtext-Beschaffung (Lyrics Scraping):** Das Tool versucht automatisch die Songtexte zum jeweiligen St√ºck aus dem Internet abzurufen. Es nutzt dazu Genius.com als Quelle, wobei zun√§chst aus den K√ºnstler-/Titeldaten eine passende Lyrics-URL gebildet wird. Falls die direkte URL nicht erfolgreich ist, wird eine Suchanfrage auf Genius ausgef√ºhrt und das erste passende Ergebnis verwendet. Die Songtexte werden als reiner Text extrahiert (mittels `Requests` + `BeautifulSoup4`) und in einer Datei `<Name>_lyrics.txt` gespeichert.
    *   **Dateiformat:** In jeder `<Name>_lyrics.txt` werden standardm√§√üig zun√§chst K√ºnstler und Titel vermerkt, gefolgt vom vollst√§ndigen Liedtext (UTF-8 kodiert).
    *   **Hinweis:** Zwischen den Anfragen wird eine kurze Pause eingelegt, um die Zielwebsite nicht zu √ºberlasten. Sollte kein Text gefunden werden, bricht das Tool die Verarbeitung des jeweiligen Songs ab (d.h. ohne Lyrics erfolgt keine Tag-Generierung ‚Äì rein instrumentale Tracks oder unbekannte Songs werden √ºbersprungen mit entsprechendem Hinweis).
4.  **Tempo-Analyse (BPM-Erkennung):** Parallel wird aus dem Audiosignal das ungef√§hre Tempo in BPM (Beats per Minute) ermittelt. Hierf√ºr kommt `Librosa` (Audio-Processing-Bibliothek) zum Einsatz: es werden Onset-Erkennung und Rhythmus-Funktionen genutzt, um das dominante Tempo in den ersten Sekunden des Songs abzusch√§tzen. Extreme Werte werden in einen sinnvollen Bereich normiert (z. B. BPM √ºber 140 werden halbiert; unter 60 ggf. verdoppelt), um halbe/doppelte Z√§hlweisen auszugleichen. Das Ergebnis (Ganzzahl) wird als BPM-Wert f√ºr die Tag-Generierung genutzt. Falls die automatische Erkennung fehlschl√§gt, versucht das Tool, eine BPM-Zahl aus dem Dateinamen zu lesen (z. B. `songname_bpm120.mp3`). Andernfalls bleibt BPM unbekannt.
5.  **Tag-Generierung (Stichwortliste):** Als zentrales Feature erzeugt das Tool pro Track eine Liste von Beschreibungstags, die Genre, Stimmung, Instrumentierung, Vocal-Typ etc. des Songs abbilden. Diese Tags werden mittels einer LLM-basierten KI generiert: Das Tool nutzt ein lokales Sprachmodell (Large Language Model) √ºber eine Ollama-API-Integration, um aus den verf√ºgbaren Informationen passende Stichw√∂rter zu ‚Äûerfinden‚Äú.
    *   Dabei wird dem Modell ein strukturierter Prompt gegeben, der alle vorhandenen Metadaten liefert: Artist, Title, BPM des Songs, ein Auszug des Songtexts (bis zu ~300 Zeichen) zur inhaltlichen Orientierung, sowie optionale Stilhinweise. Diese Stilhinweise setzen sich entweder automatisch aus vom Benutzer gew√§hlten Einstellungen (siehe Presets/Mood) oder einem manuell eingegebenen Prompt-Zusatz zusammen.
    *   Zus√§tzlich erh√§lt das Modell feste Regeln im Prompt, wie die Ausgabe aussehen soll: Es muss 12‚Äì14 Tags in Kleinschreibung und mit Bindestrich-Notation erzeugen (z. B. `dark`, `bass-heavy`, `female-vocal` etc.), unbedingt einen BPM-Tag einschlie√üen (Format `bpm-XXX`), maximal 2 Genre-Tags und mindestens je einen Tag aus den Kategorien Vocals, Instrumente, Stimmung, Rap-Styles. Eine Beispielsammlung wird im Prompt mitgegeben, damit das Modell den Stil erkennt.
    *   Als Ergebnis der Modell-Abfrage erh√§lt das Tool eine Zeichenkette mit den Tags. Diese werden nachbereitet und gefiltert (unsinnige oder zu lange Begriffe entfernt, Format vereinheitlicht) und als Liste gespeichert. Au√üerdem wird sichergestellt, dass der BPM-Tag (falls nicht vorhanden oder an sp√§terer Stelle) eingef√ºgt bzw. an den Anfang sortiert wird.
    *   Die finale Tag-Liste wird dann in einer Textdatei `<Name>_prompt.txt` gespeichert (Tags kommasepariert in einer Zeile). Diese Datei repr√§sentiert den Prompt f√ºr das ACE-Step Modell und kann z. B. bei der Musikgenerierung oder in einem Datensatz als Beschreibung verwendet werden.
6.  **Gradio Web-Oberfl√§che:** Das Tool bietet eine intuitiv bedienbare Web-UI (basierend auf Gradio), √ºber die alle obigen Schritte mit wenigen Klicks ausgef√ºhrt werden k√∂nnen. Beim Start des Tools (siehe Setup unten) √∂ffnet sich ein lokaler Webservice auf `http://127.0.0.1:7860` mit folgendem Funktionsumfang:
    *   **Datei-Scan & Start:** Ein Klick auf ‚ÄûStart Tagging‚Äú durchsucht den definierten `data/` Ordner und verarbeitet alle gefundenen Audiodateien automatisch wie oben beschrieben. Der Fortschritt wird live im Interface protokolliert (f√ºr jeden Song wird angezeigt, ob Lyrics gefunden wurden und ob Tags gespeichert wurden).
    *   **Lyrics-Option:** √úber eine Checkbox ‚ÄûOverwrite lyrics‚Äú kann gesteuert werden, ob vorhandene Lyrics-Dateien √ºberschrieben werden sollen. Ist diese Option deaktiviert, werden bereits existierende `<Name>_lyrics.txt` beibehalten (kein erneutes Herunterladen der Texte), was Zeit spart, wenn man einen Lauf wiederholt.
    *   **Genre-Presets:** In einem Dropdown ‚ÄûGenre-Preset‚Äú kann ein vordefiniertes Genre/Stil-Preset gew√§hlt werden. Diese Presets liegen als einfache Text- oder JSON-Dateien im Ordner `presets/` und enthalten bestimmte Schlagw√∂rter (z. B. ein Preset ‚ÄúHipHop‚Äù k√∂nnte Begriffe wie "90s, boom bap, underground" vorgeben). Der ausgew√§hlte Preset-Text flie√üt als Stilvorgabe in den Prompt an das Modell ein, sodass die generierten Tags stilistisch angepasst werden.
        *   **Hinweis:** Sie k√∂nnen eigene Preset-Dateien in `presets/` ablegen ‚Äì beim Start werden alle `.txt`/.`json` dort automatisch geladen.
    *   **Mood-Slider:** √úber den Schieberegler ‚Äûüé≠ Mood: Sad ‚Üî Happy‚Äú l√§sst sich die Stimmungsvorgabe variieren. Ein neutraler Wert (0.0) bedeutet keine explizite Stimmungsvorgabe. Bei positiven Werten (>0.3) wird die Stilvorgabe automatisch um einen ‚Äúhappy‚Äù-Tag erg√§nzt, bei negativen (<-0.3) um ‚Äúsad‚Äù. Dies beeinflusst z. B. die resultierenden Stimmungstags (etwa ob ‚Äûchill‚Äú/‚Äûhappy‚Äú oder ‚Äûdark‚Äú/‚Äûsad‚Äú generiert wird).
    *   **Prompt-Zusatz:** Ein Textfeld ‚Äû‚úç Prompt addition (optional)‚Äú erm√∂glicht es, manuell zus√§tzliche Stichworte oder Hinweise einzugeben, die ebenfalls an das Modell √ºbergeben werden. Ist hier Text eingetragen, √ºberschreibt er die obigen Presets/Mood-Einstellungen komplett ‚Äì man kann also gezielt eigene Beschreibungen vorgeben (z. B. ‚Äûorchestral, melancholic, strings, 80s‚Äú), um die Tag-Generierung in eine bestimmte Richtung zu lenken.
    *   **Export-Funktion:** Nach erfolgreicher Verarbeitung kann man √ºber das Interface alle generierten Dateien gesammelt exportieren. √úber ein Eingabefeld l√§sst sich ein Zielordner w√§hlen, und per ‚ÄûExport‚Äú-Button kopiert das Tool alle relevanten Dateien dorthin (d. h. die Audiodateien sowie die jeweiligen `_lyrics.txt` und `_prompt.txt`). So kann man z. B. einen kompletten Datensatz-Ordner erstellen, ohne die Originaldateien zu ver√§ndern.
7.  **Batch-Skripte & Erweiterungen:** F√ºr Fortgeschrittene liegt dem Projekt auch ein Konsolen-Einstiegspunkt bei (siehe Installation), sodass man das Tool skriptgesteuert aufrufen kann (`ace-data` Befehl). Zus√§tzlich existieren im Verzeichnis `tools/` einige Helferskripte, z. B. zum Audio-Konvertieren (`mp3_to_wav.py`, `Batch wav_to_mp3.bat`) oder experimentelle Ans√§tze zur Genre-Klassifizierung mit vortrainierten Modellen (`classify_music.py` nutzt ein HuggingFace-Modell zur Genre-Erkennung). Diese sind optional und nicht zwingend f√ºr die Hauptpipeline erforderlich. Die Kerndatenpipeline konzentriert sich auf die oben beschriebenen Schritte Lyrics ‚Üí BPM ‚Üí LLM-Tagging.

## Installation & Setup

Folgend wird die Einrichtung der Entwicklungsumgebung und Installation des ACE-Step Data-Tools erl√§utert. Es wird vorausgesetzt, dass Python und git installiert sind. Wir empfehlen die Nutzung von Miniconda zur Verwaltung der Python-Umgebung.

1.  **Repository beziehen:** Klonen Sie dieses GitHub-Repository auf Ihren Rechner:
    ```bash
    git clone https://github.com/methmx83/ace-data_tool.git
    ```
    (Alternativ k√∂nnen Sie das Projekt auch als Zip herunterladen.)
2.  **Python-Version & Umgebung:** Stellen Sie sicher, dass eine aktuelle Python-Version installiert ist. Das Tool erfordert Python ‚â• 3.7; empfohlen ist Python 3.13 (getestet auf 3.13 in der Zielumgebung).
    Erzeugen Sie eine neue Conda-Umgebung (optional, aber empfohlen) mit der passenden Python-Version:
    ```bash
    conda create -n ace-data_env python=3.13
    conda activate ace-data_env
    ```
    Dies stellt sicher, dass Abh√§ngigkeiten isoliert und kompatibel installiert werden k√∂nnen.
3.  **Abh√§ngigkeiten installieren:** Wechseln Sie ins Projektverzeichnis und installieren Sie die ben√∂tigten Python-Pakete. Alle Abh√§ngigkeiten sind in `setup.py` definiert ‚Äì Sie k√∂nnen das Tool direkt als Paket installieren:
    ```bash
    cd ace-data_tool
    pip install -e .
    ```
    Dies wird alle erforderlichen Bibliotheken (siehe unten) installieren und das Konsolenskript `ace-data` registrieren. Alternativ k√∂nnen Sie die Pakete auch manuell via `pip install -r requirements.txt` installieren, falls eine solche Liste bereitgestellt wird.
4.  **Externe Anforderungen (Ollama & Modell):** F√ºr die Tag-Generierung muss ein Ollama-Server mit dem ben√∂tigten Sprachmodell laufen. Installieren Sie daher Ollama (Version 0.9.6 oder neuer, siehe Ollama Doku) auf Ihrem System. Laden Sie anschlie√üend ein kompatibles Sprachmodell in Ollama. Im standardm√§√üigen Config-File (`config/config.json`) ist der Modellname `"deep-x1_q4:latest"` eingetragen ‚Äì dies deutet auf ein lokales Modell hin (z. B. ein quantisiertes Llama-Derivat). Stellen Sie sicher, dass entweder dieses Modell verf√ºgbar ist oder passen Sie den `model_name` in der Config an ein installiertes Modell an. Starten Sie den Ollama-Dienst, damit die API unter `http://localhost:11434` erreichbar ist (Standardport von Ollama).
    *   **Hinweis:** Ollama ist plattform√ºbergreifend verf√ºgbar (Windows erfordert evtl. WSL oder eine native Portierung, Version 0.9.6 unterst√ºtzt Windows nativ). Ohne laufenden LLM-Server kann die Tag-Generierung nicht erfolgen ‚Äì in diesem Fall w√ºrde das Tool bei jedem Song nach den Lyrics stoppen.
5.  **Ordner vorbereiten:** Legen Sie einen Ordner `data` im Projektverzeichnis an (falls nicht bereits vorhanden) und kopieren Sie Ihre Audiodateien dort hinein. Sie k√∂nnen auch die Unterordner-Struktur beibehalten, falls die Songs schon nach Alben/Genres etc. sortiert sind ‚Äì der Scan l√§uft rekursiv.
6.  **Starten des Tools:** Nach erfolgreicher Installation der Pakete und Einrichtung des Ollama-Modells k√∂nnen Sie die Anwendung starten. Unter Windows wurde bei Installation via pip das Skript `ace-data` registriert. F√ºhren Sie in Ihrem aktivierten Env aus:
    ```bash
    ace-data
    ```
    Dadurch wird das Gradio-Webinterface hochgefahren. Nach einigen Sekunden sollte in der Konsole die Ausgabe `Running on local URL: http://127.0.0.1:7860` erscheinen. √ñffnen Sie diese Adresse im Browser, um zur Benutzeroberfl√§che zu gelangen.
    *   **(Sollte der Befehl nicht gefunden werden, pr√ºfen Sie die Installation oder nutzen Sie alternativ `python -m webui.app` im Projektordner.)**
7.  **Nutzung √ºber die UI:** In der Web-Oberfl√§che k√∂nnen Sie nun die gew√ºnschten Einstellungen vornehmen (siehe oben: Overwrite Lyrics, Preset, Mood, Prompt) und dann ‚ÄûStart Tagging‚Äú klicken.
    Das Tool verarbeitet daraufhin alle Dateien im `data/`-Ordner. √úberwachen Sie die Log-Ausgaben, um etwaige Probleme (fehlende Lyrics, Modell-Fehler etc.) zu erkennen. Bei erfolgreichem Durchlauf finden Sie anschlie√üend f√ºr jeden Track im `data/`-Verzeichnis zwei neue Dateien: `<Name>_lyrics.txt` und `<Name>_prompt.txt`. Nutzen Sie optional die Export-Funktion im UI, um alle Ergebnisse gesammelt in einen anderen Ordner zu kopieren (praktisch, um die Audios plus Tags z.B. in einen Trainingsdatensatz zu √ºberf√ºhren).

## Abh√§ngigkeiten

Das Projekt verwendet aktuelle Python-Bibliotheken, um Audioverarbeitung, Web-Scraping und ML-Integration umzusetzen. Eine gek√ºrzte √úbersicht der wichtigsten Abh√§ngigkeiten und Tools:

*   **Python ‚â• 3.10** (empfohlen 3.13) ‚Äì neuere Versionen werden empfohlen, um Kompatibilit√§t mit allen Libraries sicherzustellen.
*   **Gradio (v5.35 oder h√∂her)** ‚Äì f√ºr die WebUI. Erm√∂glicht einfache Erstellung interaktiver Oberfl√§chen zur Steuerung des Workflows.
*   **Librosa** ‚Äì f√ºr Audioanalyse (insb. Tempo/BPM-Erkennung). Intern nutzt Librosa `numpy`, `scipy`, `soundfile` etc., um Audiodaten zu laden und zu verarbeiten.
*   **SoundFile** ‚Äì zum Laden von Audiofiles (Librosa-Backend, erfordert die systemweite Bibliothek `libsndfile` ‚Äì bei Installation √ºber Conda wird diese automatisch mit installiert, bei pip ist sie im `pysoundfile` Paket enthalten).
*   **Requests + BeautifulSoup4** ‚Äì zum Herunterladen der Songtext-Webseiten und Parsen des HTML-Inhalts von Genius.
*   **Tinytag** ‚Äì zum Auslesen von Audiodatei-Metadaten (K√ºnstler, Titel, Album etc. aus g√§ngigen Formaten wie MP3, FLAC, M4A).
*   **NLTK (Natural Language Toolkit)** ‚Äì f√ºr Sentiment-Analyse und Text-Normalisierung der Lyrics. Das Tool l√§dt bei erstem Gebrauch die Sentiment-Daten (`vader_lexicon`) und Stopwortlisten herunter.
*   **numpy, scipy, matplotlib** ‚Äì √ºbliche Pakete f√ºr numerische Berechnungen; `matplotlib` wird im Tool selbst kaum verwendet (evtl. war es f√ºr Debugging vorgesehen).
*   **Ollama** ‚Äì externer Dienst f√ºr LLM-Abfragen. Dies ist keine Python-Bibliothek, sondern eine Laufzeit, die lokal LLMs ausf√ºhren kann (√§hnlich einem lokalen ChatGPT-Server). Es wird via HTTP angesprochen. Bitte installieren Sie Ollama separat, wie oben beschrieben. Alternativ k√∂nnten Sie theoretisch auch eigene API-Endpunkte eines anderen LLM (z. B. OpenAI API) nutzen, allerdings ist das Tool f√ºr das Ollama-Protokoll vorkonfiguriert.
*   **CUDA 12 (optional, f√ºr GPU-Unterst√ºtzung im LLM-Betrieb)** ‚Äì Wenn das verwendete Sprachmodell GPU-Beschleunigung nutzt (z. B. durch Ollama/llama.cpp mit CUDA-Unterst√ºtzung), sollten entsprechende NVIDIA-Treiber und CUDA-Toolkit installiert sein. Das empfohlene Setup nutzt CUDA 12.9 unter Windows f√ºr optimale Performance mit neueren NVIDIA-Karten.

Die Installation der Python-Abh√§ngigkeiten erfolgt, wie oben gezeigt, √ºber `pip`/Conda. Achten Sie darauf, in der passenden Umgebung zu installieren. F√ºr Windows-Benutzer ist es empfehlenswert, Visual Studio 2022 Build Tools zu installieren (wie in der empfohlenen Konfiguration vorgesehen), da manche Python-Pakete (falls kein Wheel verf√ºgbar) einen C++-Compiler ben√∂tigen. In unserem Fall werden aber die meisten Libraries als vorkompilierte Wheels installiert, sodass kein manuelles Kompilieren n√∂tig sein sollte.

**Hardware-Empfehlung:** Das Tool wurde unter Windows 10 Pro x64 mit einem Intel i9 (24 Threads) und einer NVIDIA RTX 4070 (12 GB VRAM) getestet. 64 GB RAM standen zur Verf√ºgung. √Ñhnliche oder etwas schw√§chere Konfigurationen sollten funktionieren. Mindestens 8‚Äì12 GB Grafikspeicher sind ratsam, damit das LLM-Modell in den GPU-Speicher passt ‚Äì siehe Abschnitt unten zu Modellkompatibilit√§t.

## Beispiele zur Nutzung

Im normalen Gebrauch ist kein zus√§tzliches Coding n√∂tig ‚Äì das Tool erledigt alles auf Knopfdruck √ºber die UI. Dennoch seien hier ein paar Anwendungsbeispiele und typische Outputs gezeigt, um das Verhalten zu illustrieren:

1.  **Basic Run (alle Dateien verarbeiten):** Nachdem Sie Ihre MP3s in `data/` gelegt haben, starten Sie `ace-data`. Im Browser-UI k√∂nnen Sie z.B. das Genre-Preset auf ‚ÄúHipHop‚Äù setzen, den Mood-Slider auf leicht positiv (+0.5) und dann auf Start Tagging klicken. Angenommen, im Ordner befindet sich eine Datei `Song1.mp3` (Artist: Imagine Dragons, Title: Believer).
    *   Das Tool wird: den Songtext laden, BPM berechnen (z. B. ~125), und Tags generieren. In der Log-Anzeige erscheint etwa:
        ```
        Song1.mp3 - ‚úì Saved lyrics and prompt
        BPM: 125 - TAGS: bpm-125, male-vocal, rock, drums, energetic,...
        ```
        Dies signalisiert, dass die Dateien erfolgreich erstellt wurden. Im Dateisystem finden Sie nun:
        *   `Song1_lyrics.txt` ‚Äì den vollst√§ndigen Liedtext zu ‚ÄúBeliever‚Äù, beginnend mit z.B. ‚ÄúK√ºnstler: Imagine Dragons\nTitel: Believer\n\nFirst things first...‚Äù.
        *   `Song1_prompt.txt` ‚Äì die Tags, z.B.:
            ```
            bpm-125, male-vocal, rock, guitars, aggressive, anthem, pop-rock, upbeat, stadium, american
            ```
            (Dies ist ein fiktives Beispiel von ~10 Tags; die tats√§chliche Liste kann leicht variieren. Wichtig ist das Format: klein, komma-getrennt, ggf. Bindestriche statt Leerzeichen.)
2.  **Overwrite/Retry Lyrics:** Wenn ein Song beim ersten Lauf keine Lyrics gefunden hatte (im Log erscheint etwa ‚Äú‚úó Keine Lyrics gefunden.‚Äù), k√∂nnen Sie manuell korrigieren (z. B. ID3-Tags des Files verbessern oder den Songtext selbst als `<Dateiname>_lyrics.txt` im Ordner ablegen) und dann das Tool erneut ausf√ºhren. Aktivieren Sie in diesem Fall die Option "Overwrite lyrics", damit das Tool trotz vorhandener Lyrics-Datei nochmal versucht, den Text online abzurufen (oder Ihre manuell erstellte Datei √ºberschreibt). Ohne diese Option w√ºrde es vorhandene `_lyrics.txt` beibehalten.
3.  **Nutzung als Python-Modul:** Alle Kernfunktionen sind auch programmatisch nutzbar.
    Beispielweise k√∂nnen Sie in einem eigenen Python-Skript auf die Module zugreifen, wenn Sie etwas automatisieren m√∂chten:
    ```python
    from scripts.bpm import get_bpm
    bpm_val = get_bpm("audio/path/song.wav")
    print("Detected BPM:", bpm_val)

    from scripts.lyrics import fetch_and_save_lyrics
    fetch_and_save_lyrics("Imagine Dragons", "Believer", "output_folder/Believer_lyrics.txt")

    from scripts.tagger import generate_tags, save_tags
    tags = generate_tags("output_folder/Believer.mp3", prompt_guidance="rock, energetic")
    save_tags("output_folder/Believer.mp3", tags)
    print("Generated Tags:", tags)
    ```
    Dieser exemplarische Code w√ºrde den BPM eines Songs bestimmen, Lyrics von Genius laden und Tags generieren, ohne die Gradio-Oberfl√§che zu nutzen. Beachten Sie, dass `generate_tags` Zugriff auf den laufenden LLM-Server erfordert ‚Äì stellen Sie also sicher, dass Ollama mit dem Modell l√§uft, sonst wird ein Timeout/Fehler auftreten. Die Funktion `save_tags` speichert die Tags in der Datei `<Song>_prompt.txt` und sorgt daf√ºr, dass ggf. die Lyrics-Datei von technischen Artefakten bereinigt wird (Entfernung von Sonderzeichen/Platzhaltern aus dem Text).
4.  **Exportierte Datensatz-Struktur:** Wenn Sie die Export-Funktion nutzen oder manuell den `data/` Ordner nach der Verarbeitung woanders hinkopieren, erhalten Sie einen Datensatz, der f√ºr Trainingszwecke direkt genutzt werden kann. Ein m√∂glicher Ausschnitt der Ordnerstruktur nach Verarbeitung k√∂nnte so aussehen:
    ```
    data/
    ‚îú‚îÄ‚îÄ Album1/
    ‚îÇ   ‚îú‚îÄ‚îÄ Track01.mp3
    ‚îÇ   ‚îú‚îÄ‚îÄ Track01_lyrics.txt
    ‚îÇ   ‚îî‚îÄ‚îÄ Track01_prompt.txt
    ‚îÇ   ‚îî‚îÄ‚îÄ Track02.mp3
    ‚îÇ       ‚îú‚îÄ‚îÄ Track02_lyrics.txt
    ‚îÇ       ‚îî‚îÄ‚îÄ Track02_prompt.txt
    ‚îî‚îÄ‚îÄ Album2/
        ‚îú‚îÄ‚îÄ SongA.mp3
        ‚îú‚îÄ‚îÄ SongA_lyrics.txt
        ‚îî‚îÄ‚îÄ SongA_prompt.txt
    ```
    Jeder Song liegt nun mit zugeh√∂rigem Lyrics- und Prompt-Textfile vor. Diese Textdaten k√∂nnen z.B. ins Training eines ACE-Step Modells eingespeist werden (Lyrics als gew√ºnschter Gesangstext, Tags als musikalischer Kontext/Style). Beachten Sie, dass das Tool keine eigentlichen Audio-Features extrahiert ‚Äì es generiert ‚Äûnur‚Äú beschreibende Meta-Informationen.

## Modellkompatibilit√§t & Hardware-Anforderungen

Die Qualit√§t und Geschwindigkeit der Tag-Generierung h√§ngt stark vom eingesetzten Sprachmodell (LLM) ab. Das ACE-Step Data-Tool wurde bewusst so gebaut, dass es kein externes Cloud-API ben√∂tigt, sondern mit einem lokalen Modell arbeitet ‚Äì so bleiben auch urheberrechtlich gesch√ºtzte Songtexte auf dem eigenen Rechner. Standardm√§√üig ist in `config/config.json` der Modellname `deep-x1_q4` eingestellt. Dies sollte ein kompatibles Modell im Ollama-Format sein (z. B. ein Derivat eines LLaMA-2 Modells mit ~7‚Äì13B Parametern, quantisiert auf 4 Bit f√ºr geringeren VRAM-Verbrauch).

*   **Kompatible Modelle:** In der Regel eignen sich Chat-optimierte Modelle (z. B. LLaMA2-Chat, GPT-J, GPT-4-X Alpaca o.√Ñ.), die Anweisungen folgen k√∂nnen. Wichtig ist, dass das Modell ausreichend Kontextl√§nge (>= 4k Tokens) und Kompetenz hat, um auf Basis kurzer Lyrics + Regeln sinnvolle Tags zu erzeugen. Kleinere Modelle (<7B Parameter) k√∂nnten M√ºhe haben, konsistente Genre/Mood-Tags zu liefern. Im Test lieferte ein LLaMA2-basiertes Modell (~7B, 4-bit) zufriedenstellende Ergebnisse.
    *   Theoretisch kann jedes √ºber Ollama verf√ºgbare Modell verwendet werden ‚Äì um es zu √§ndern, passen Sie `model_name` in der Config an. Achten Sie darauf, dass das Modell die im Prompt vorgegebenen Markdown-Formatierungen und Rollen (‚Äúsystem‚Äù und ‚Äúuser‚Äù) versteht (die meisten neueren Chat-LLMs tun dies).
*   **Hardware & Performance:** Das vorgesehene Modellsetup ben√∂tigt eine potente GPU. Mit der empfohlenen NVIDIA RTX 4070 (12GB VRAM) konnte das in `config.json` genannte Modell z√ºgig geladen und Abfragen innerhalb von wenigen Sekunden pro Song beantwortet werden. Sollten Sie eine GPU mit weniger Speicher verwenden (z. B. 8 GB), k√∂nnte das Laden fehlschlagen oder der Modell-Server automatisch auf CPU-Betrieb ausweichen.
    *   **Warnung:** Im CPU-Modus dauert die Tag-Generierung deutlich l√§nger (mehrere Minuten pro Song sind m√∂glich, abh√§ngig vom Modell).
    *   Falls nur wenig GPU-Speicher vorhanden ist, erw√§gen Sie:
        *   ein kleineres bzw. st√§rker komprimiertes Modell (z. B. 4-Bit-Quantisierung, 7B Parameter oder weniger),
        *   oder nutzen Sie Ollamas Optionen wie `--gpu-offloading` / `--cpu-offload`, um Teile des Modells auszulagern.
    *   Grunds√§tzlich gilt: ‚â•12 GB VRAM sind empfehlenswert, um fl√ºssig arbeiten zu k√∂nnen. Eine Multi-Core-CPU beschleunigt nebenbei auch das Audio-Processing (`Librosa`) und das HTML-Parsen, was aber meist nicht der Engpass ist.
*   **Einschr√§nkungen:** Beachten Sie, dass die Qualit√§t der automatisch generierten Tags nicht perfekt ist ‚Äì sie h√§ngen vom Modellwissen und den Lyrics ab. Das Tool priorisiert Rap/Hip-Hop-Tags, wenn es Rap-Begriffe erkennt (siehe `Moods.md` f√ºr die vordefinierten Listen an Genres, Moods, Instrumenten, Rap-Stilen). Bei sehr ungew√∂hnlichen oder instrumentalen St√ºcken kann das Modell danebenliegen. Zudem werden Songs ohne auffindbaren Liedtext derzeit nicht getaggt ‚Äì d.h. rein instrumentale Tracks erhalten keine Ausgabe au√üer dem Hinweis, dass Lyrics fehlen. Diese Einschr√§nkung ist bewusst, da die Tags stark von lyrischen Inhalten und Stimmungen abh√§ngen. In zuk√ºnftigen Versionen k√∂nnte man hier Audio-Feature-basierte Tagging-Modelle einbinden (siehe `tools/classify_music.py` f√ºr Ans√§tze), aber Stand Juli 2025 konzentriert sich das Tool auf textbasierte Metadaten.

## Projektstruktur

Um den Einstieg in den Code zu erleichtern, hier eine vereinfachte √úbersicht der Repository-Struktur:

```
ace-data_tool/
‚îú‚îÄ‚îÄ webui/
‚îÇ   ‚îî‚îÄ‚îÄ app.py - Gradio App (UI-Layout, Start/Stop, Button-Callbacks)
‚îú‚îÄ‚îÄ scripts/ - Kernfunktionen zur Datenverarbeitung:
‚îÇ   ‚îú‚îÄ‚îÄ lyrics.py - Lyrics-Scraping (Genius API Scraper)
‚îÇ   ‚îú‚îÄ‚îÄ bpm.py - BPM-Detection mit Librosa
‚îÇ   ‚îú‚îÄ‚îÄ moods.py - Textanalyse (Sentiment, Tag-Bereinigung, Preset-Lader)
‚îÇ   ‚îî‚îÄ‚îÄ tagger.py - Tag-Generator (LLM-API Aufruf, Prompt-Definition)
‚îú‚îÄ‚îÄ include/ - Hilfsfunktionen und Konfiguration:
‚îÇ   ‚îú‚îÄ‚îÄ preset_loader.py - L√§dt Genre-Presets aus dem Ordner presets/
‚îÇ   ‚îú‚îÄ‚îÄ clean_lyrics.py - Bereinigt Lyrics (Entfernt Sonderzeichen, Notizen)
‚îÇ   ‚îú‚îÄ‚îÄ metadata.py, write_metadata.py - Alternativer Metadaten-Handler (JSON Export)
‚îÇ   ‚îî‚îÄ‚îÄ prompt_editor.py - (optional, UI-Element f√ºr Prompt-Bearbeitung)
‚îú‚îÄ‚îÄ presets/ - Vordefinierte Preset-Dateien (Genres, Stimmungen etc., vom Nutzer erweiterbar)
‚îú‚îÄ‚îÄ tools/ - Zus√§tzliche Tools/Optionals:
‚îÇ   ‚îú‚îÄ‚îÄ convert_tools/ - Audio-Konvertierung (mp3 <-> wav Batch-Skripte)
‚îÇ   ‚îî‚îÄ‚îÄ wave_processing/ - Audioanalyse (z.B. Genre-Klassifikation mit ML, experimentell)
‚îú‚îÄ‚îÄ config/
‚îÇ   ‚îî‚îÄ‚îÄ config.json - Konfigurationsdatei (Pfad zum Input-Ordner, LLM-Modellname, API-URL, Retry-Einstellungen)
‚îú‚îÄ‚îÄ README.md - (Diese Dokumentation)
‚îî‚îÄ‚îÄ System_Spezifikationen_music-scraper.md - Empfohlene Systemumgebung & Hardwaredetails
```

Jeder Bereich des Codes ist in Module gekapselt. Die UI-Schicht (`webui/app.py`) ruft Funktionen aus den Scripts auf und vermittelt zwischen Benutzeroptionen und Verarbeitung. In den Scripts liegen die Kernlogiken f√ºr jeden Verarbeitungsschritt. Besonders `tagger.py` ist komplexer, da hier die Kommunikation mit dem LLM erfolgt und ein mehrstufiges Fehlerhandling implementiert ist (inkl. Reload/Reset des Modells bei Problemen, mehrfache Versuche bis zu einer `retry_count`-Grenze). Die Include-Utilities k√ºmmern sich um Datenvor- und -nachbereitung, w√§hrend Presets und Config die anpassbaren Teile darstellen, die Sie ohne Code-√Ñnderung modifizieren k√∂nnen (z.B. eigene Presets hinzuf√ºgen oder ein anderes Modell in `config.json` eintragen).

## Schlusswort

Mit ACE-Step Data-Tool k√∂nnen Sie in wenigen Schritten aus einer Sammlung von Songs einen reich annotierten Datensatz erstellen. Das Tool nimmt Ihnen das m√ºhsame manuelle Zusammensuchen von Liedtexten und das Erstellen von Tags ab und standardisiert das Format der Metadaten f√ºr weitere Verwendung im ACE-Step-Projekt oder √§hnlichen Vorhaben. Bei Fragen oder Problemen konsultieren Sie bitte die Issues in diesem Repository oder wenden Sie sich an die Entwickler.


```

